{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import fiona\n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from sqr.core.shape import make_gdf_square_data, find_neighbor_shapes\n",
    "from sqr.core.shape import label2coord, polygon_from_north_east\n",
    "from sqr.pre_assign import pre_partition_area, assign_cells_partition, merge_insufficient\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "Load kvadratnet with population data into HDF store: 'data/parsed/kvadrat_data.hdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_file = 'DST/Antal personer pr. celle.xlsx'\n",
    "\n",
    "for dst_sheetname in ['_10km','_1km','_100m']:\n",
    "    print(dst_sheetname)\n",
    "    in_df = pd.read_excel(pop_file, sheetname=dst_sheetname)\n",
    "    in_df.to_hdf('DST/personer_celler.hdf', key = dst_sheetname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make HDF format of 100x100 kvadratnet and append data\n",
    "\n",
    "Note this should be only run the first time using this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = gpd.read_file('raw/DKN_100m_euref89.shp').iloc[:,:1]\n",
    "dk_bornholm = gpd.read_file('data/raw/DKN_bholm_100m_euref89.shp').iloc[:,:1]\n",
    "\n",
    "pd.concat([dk, dk_bornholm],\n",
    "          ignore_index=True)\\\n",
    "  .KN100mDK\\\n",
    "  .to_hdf(data='data/parsed/kvadrat_data.hdf', \n",
    "          key='cells100')\n",
    "\n",
    "KN100mDK = pd.read_hdf('data/parsed/kvadrat_data.hdf', key='cells100')\n",
    "\n",
    "coords = pd.DataFrame(np.array(KN100mDK.str.split('_').tolist())[:,1:], \n",
    "                      columns = ['n','e'])\n",
    "\n",
    "\n",
    "coords['e_cent'] = (coords.e.astype(int)*100+50).astype(np.int32)    \n",
    "coords['n_cent'] = (coords.n.astype(int)*100+50).astype(np.int32)\n",
    "\n",
    "p1 = pyproj.Proj(fiona.crs.from_epsg(25832))\n",
    "p2 = pyproj.Proj(fiona.crs.from_epsg(4326))    \n",
    "    \n",
    "gps_coords = pyproj.transform(p1, p2, coords.e_cent.values, coords.n_cent.values)\n",
    "gps_coords = pd.DataFrame(np.array(gps_coords).T, columns = ['lon_cent','lat_cent'])\n",
    "\n",
    "all_coords = pd.concat([KN100mDK,coords,gps_coords],axis=1)\n",
    "\n",
    "all_coords.to_hdf('data/parsed/kvadrat_data.hdf', key='cells100_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign square to municipality shapes\n",
    "\n",
    "### Load data\n",
    "Load square cell population data and perform various calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pers = pd.read_hdf('data/parsed/personer_celler.hdf', key='_100m').iloc[1:]\n",
    "year_cols = list(map(str,range(1986,2016)))\n",
    "\n",
    "pers_years = pers[year_cols]\n",
    "pers['minimum'] = pers_years.min(axis=1)\n",
    "pers['mean'] = pers_years.fillna(0).mean(axis=1)\n",
    "\n",
    "# new construction year\n",
    "pers['zero'] = pers_years.isnull().max(axis=1)\n",
    "zeros = pers_years[pers.zero].isnull()\n",
    "zeros_t = zeros.T\n",
    "inhabit = (zeros_t.shift(1).fillna(False) & (~zeros_t))\n",
    "inhabit_single = (inhabit.sum(axis=0)==1) & (~zeros.iloc[:,-1])\n",
    "inhabit_year = zeros_t\\\n",
    "                .loc[:,inhabit_single]\\\n",
    "                .idxmin()\\\n",
    "                .rename('inhabit_year')\\\n",
    "                .astype(int)\n",
    "pers = pers.join(inhabit_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load square municipal data and combine with square cell population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kommuner = gpd.read_file('data/shape/KOMMUNE.shp')\n",
    "\n",
    "pers = pd.read_hdf('data/parsed/personer_celler.hdf', key='_100m').iloc[1:]\n",
    "year_cols = list(map(str,range(1986,2016)))\n",
    "\n",
    "pers_years = pers[year_cols]\n",
    "pers['minimum'] = pers_years.min(axis=1)\n",
    "pers['mean'] = pers_years.fillna(0).mean(axis=1)\n",
    "\n",
    "# new construction year\n",
    "pers['zero'] = pers_years.isnull().max(axis=1)\n",
    "zeros = pers_years[pers.zero].isnull()\n",
    "zeros_t = zeros.T\n",
    "inhabit = (zeros_t.shift(1).fillna(False) & (~zeros_t))\n",
    "inhabit_single = (inhabit.sum(axis=0)==1) & (~zeros.iloc[:,-1])\n",
    "inhabit_year = zeros_t\\\n",
    "                .loc[:,inhabit_single]\\\n",
    "                .idxmin()\\\n",
    "                .rename('inhabit_year')\\\n",
    "                .astype(int)\n",
    "pers = pers.join(inhabit_year)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "all_squares = pd.read_hdf('data/parsed/kvadrat_data.hdf', key='cells100_data')\n",
    "all_squares.rename(columns = {'lon_cent':'lon','lat_cent':'lat'}, inplace=True)\n",
    "all_squares.e = all_squares.e.astype(int)\n",
    "all_squares.n = all_squares.n.astype(int)\n",
    "\n",
    "all_gdf = make_gdf_square_data(all_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign square cells to municipalities (municipalities after kommunalreformen 2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assignments = assign_cells_partition(kommuner, all_gdf)\n",
    "\n",
    "assignment_dict = assignments\\\n",
    "                    .groupby('assignment')\\\n",
    "                    .apply(lambda g: g.index.tolist())\\\n",
    "                    .to_dict()\n",
    "\n",
    "extra_cols = ['minimum','mean','shift_year','ddkncelle100m']            \n",
    "            \n",
    "for idx in assignment_dict.keys():\n",
    "    assignment_idxs = assignment_dict[idx]\n",
    "    \n",
    "    out_df = all_gdf\\\n",
    "            .loc[assignment_idxs]\\\n",
    "            .drop('geometry', axis=1)\\\n",
    "            .reset_index()\\\n",
    "            .rename(columns={'index':'square_idx'})\n",
    "    \n",
    "    out_df = out_df.merge(pers[extra_cols+year_cols], \n",
    "                          right_on='ddkncelle100m',\n",
    "                          left_on='KN100mDK', \n",
    "                          how='left')\\\n",
    "                .drop('ddkncelle100m',axis=1)\n",
    "    \n",
    "    pd.DataFrame(out_df).to_hdf('data/parsed/sqr_mun.hdf', key='sqidx%i'% idx)    \n",
    "    \n",
    "# check no cells is overlapping for ANY pair of municipality indices\n",
    "\n",
    "errors = []\n",
    "\n",
    "for (i1,i2) in mun_neighbor:\n",
    "    cells1 = cell_assignment[i1]['within'] + list(cell_assignment[i1]['touching'])\n",
    "    cells2 = cell_assignment[i2]['within'] + list(cell_assignment[i2]['touching'])\n",
    "    \n",
    "    if np.intersect1d(cells1,cells2).size>0:\n",
    "        errors+= [(i1,i2)]\n",
    "        \n",
    "print (errors)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition municipality shapes into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kommuner = gpd.read_file('data/shape/KOMMUNE.shp')\n",
    "\n",
    "mun_pop_min = {}\n",
    "mun_pop_avg = {}\n",
    "mun_cell_count = {}\n",
    "\n",
    "for idx in kommuner.index:\n",
    "    mun_data = \\\n",
    "        pd.read_hdf('data/parsed/sqr_mun.hdf', key='sqidx%i'% idx)\n",
    "    mun_pop_min[idx] = mun_data.minimum.sum()    \n",
    "    mun_pop_avg[idx] = mun_data['mean'].sum()    \n",
    "    mun_cell_count[idx] = mun_data.shape[0]\n",
    "                \n",
    "kommuner['minimum_total'] = pd.Series(mun_pop_min)\n",
    "kommuner['mean_total'] = pd.Series(mun_pop_avg)\n",
    "kommuner['cell_count'] = pd.Series(mun_cell_count)\n",
    "\n",
    "kommuner['to_assign'] = kommuner.minimum_total>100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select =  kommuner[(kommuner.to_assign) & (kommuner.cell_count>25000)]\n",
    "\n",
    "for idx in tqdm(select.index.tolist()):\n",
    "    print(idx)\n",
    "    origin_geom= kommuner.iloc[idx].geometry\n",
    "    mun_df = pd.read_hdf('data/parsed/sqr_mun.hdf', 'sqidx%i' % idx)\n",
    "    mun_gdf = make_gdf_square_data(mun_df)\n",
    "    pre_part = pre_partition_area(mun_df, origin_geom)\n",
    "    \n",
    "    pre_part_suff = merge_insufficient(pre_part)\n",
    "    \n",
    "    assignment = assign_cells_partition(pre_part, mun_gdf)\n",
    "\n",
    "    mun_df = mun_df\\\n",
    "                .join(assignment)\\\n",
    "                .drop('geometry', axis=1)\n",
    "\n",
    "    for sub_idx, sub_df in mun_df.groupby('assignment'):\n",
    "        out_key = 'sqidx%i_%i' % (idx, sub_idx)\n",
    "        sub_df.to_hdf('data/parsed/sqr_mun_sub.hdf', key = out_key)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
