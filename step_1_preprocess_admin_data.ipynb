{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Preprocessing administrative data\n",
    "\n",
    "This is the first step in the computation. Running this notebook requires you to contact Statistics Denmark for data on population per square. Moreover, you also need to generate the grid data. \n",
    "\n",
    "Throughout we use various packages for network and spatial data. Running the following conda install script should be sufficient to get the required packages. You can either with running the following line. Another option is to install via the .yml file using conda.\n",
    "\n",
    "`conda install -c conda-forge pandas geopandas pyproj tqdm networkx igraph louvain ipyparallel nose -y`\n",
    "\n",
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import fiona\n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from sqr.core.shape import make_gdf_square_data, find_neighbor_shapes\n",
    "from sqr.core.shape import label2coord, polygon_from_north_east\n",
    "from sqr.pre_assign import pre_partition_area, assign_cells_partition, merge_insufficient\n",
    "from sqr.miscellaneous import read_parse_mun\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "Before proceeding you need to contact Statistics Denmark (DST) about getting access to 'Antal personer pr. celle' spreadsheet.\n",
    "\n",
    "Load kvadratnet with population data into HDF store: 'data/parsed/kvadrat_data.hdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/raw/', exist_ok=True)\n",
    "\n",
    "pop_file = 'data/raw/Antal personer pr. celle.xlsx'\n",
    "\n",
    "for dst_sheetname in ['_10km','_1km','_100m']:\n",
    "    print(dst_sheetname)\n",
    "    in_df = pd.read_excel(pop_file, sheetname=dst_sheetname)\n",
    "    in_df.to_hdf('data/parsed/personer_celler.hdf', key = dst_sheetname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding you need to use GridFactory, available [here](http://www.routeware.dk/download.php). This software should be used to generate generate the Danish shapes for whole Denmark without Bornholm and Bornholm on its own. The level of square net measure should be 100m. The shape file collection should be put in the path 'data/shape/'. Note that the two set of files for rest of Denmark and Bornholm should be named respectively `DKN_100m*` and `DKN_Bornholm_100m*`.\n",
    "\n",
    "Make HDF format of 100x100 kvadratnet and append data\n",
    "\n",
    "Note this should be only run the first time using this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/parsed/', exist_ok=True)\n",
    "\n",
    "dk = gpd.read_file('data/shape/DKN_100m_euref89.shp').iloc[:,:1]\n",
    "dk_bornholm = gpd.read_file('data/shape/DKN_Bornholm_100m_euref89.shp').iloc[:,:1]\n",
    "\n",
    "pd.concat([dk, dk_bornholm], ignore_index=True)\\\n",
    "  .KN100mDK\\\n",
    "  .to_hdf(path_or_buf='data/parsed/kvadrat_data.hdf', \n",
    "          key='cells100')\n",
    "\n",
    "KN100mDK = pd.read_hdf('data/parsed/kvadrat_data.hdf', key='cells100')\n",
    "\n",
    "coords = pd.DataFrame(np.array(KN100mDK.str.split('_').tolist())[:,1:], \n",
    "                      columns = ['n','e'])\n",
    "\n",
    "\n",
    "coords['e_cent'] = (coords.e.astype(int)*100+50).astype(np.int32)    \n",
    "coords['n_cent'] = (coords.n.astype(int)*100+50).astype(np.int32)\n",
    "\n",
    "p1 = pyproj.Proj(fiona.crs.from_epsg(25832))\n",
    "p2 = pyproj.Proj(fiona.crs.from_epsg(4326))    \n",
    "    \n",
    "gps_coords = pyproj.transform(p1, p2, coords.e_cent.values, coords.n_cent.values)\n",
    "gps_coords = pd.DataFrame(np.array(gps_coords).T, columns = ['lon_cent','lat_cent'])\n",
    "\n",
    "all_coords = pd.concat([KN100mDK,coords,gps_coords],axis=1)\n",
    "\n",
    "all_coords.to_hdf('data/parsed/kvadrat_data.hdf', key='cells100_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign square to municipality shapes\n",
    "\n",
    "### Load data\n",
    "Load square cell population data and perform various calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers = pd.read_hdf('data/parsed/personer_celler.hdf', key='_100m').iloc[1:]\n",
    "year_cols = list(map(str,range(1986,2016)))\n",
    "\n",
    "pers_years = pers[year_cols]\n",
    "pers['minimum'] = pers_years.min(axis=1)\n",
    "pers['mean'] = pers_years.fillna(0).mean(axis=1)\n",
    "\n",
    "# years where cells have new construction\n",
    "pers['zero'] = pers_years.isnull().max(axis=1)\n",
    "zeros = pers_years[pers.zero].isnull()\n",
    "zeros_t = zeros.T\n",
    "inhabit = (zeros_t.shift(1).fillna(False) & (~zeros_t))\n",
    "inhabit_single = (inhabit.sum(axis=0)==1) & (~zeros.iloc[:,-1])\n",
    "inhabit_year = zeros_t\\\n",
    "                .loc[:,inhabit_single]\\\n",
    "                .idxmin()\\\n",
    "                .rename('inhabit_year')\\\n",
    "                .astype(int)\n",
    "pers = pers.join(inhabit_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load municipal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kommuner = gpd.read_file('data/shape/KOMMUNE.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load square municipal data and combine with square cell population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_squares = pd.read_hdf('data/parsed/kvadrat_data.hdf', key='cells100_data')\n",
    "all_squares.rename(columns = {'lon_cent':'lon','lat_cent':'lat'}, inplace=True)\n",
    "all_squares.e = all_squares.e.astype(int)\n",
    "all_squares.n = all_squares.n.astype(int)\n",
    "\n",
    "all_gdf = make_gdf_square_data(all_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign square cells to municipalities (municipalities after kommunalreformen 2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = assign_cells_partition(kommuner, all_gdf)\n",
    "\n",
    "assignment_dict = assignments\\\n",
    "                    .groupby('assignment')\\\n",
    "                    .apply(lambda g: g.index.tolist())\\\n",
    "                    .to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cols = ['minimum','mean','inhabit_year','ddkncelle100m']            \n",
    "            \n",
    "for idx in assignment_dict.keys():\n",
    "    assignment_idxs = assignment_dict[idx]\n",
    "    \n",
    "    out_df = all_gdf\\\n",
    "            .loc[assignment_idxs]\\\n",
    "            .drop('geometry', axis=1)\\\n",
    "            .reset_index()\\\n",
    "            .rename(columns={'index':'square_idx'})\n",
    "    \n",
    "    out_df = out_df.merge(pers[extra_cols+year_cols], \n",
    "                          right_on='ddkncelle100m',\n",
    "                          left_on='KN100mDK', \n",
    "                          how='left')\\\n",
    "                .drop('ddkncelle100m',axis=1)\n",
    "    \n",
    "    pd.DataFrame(out_df).to_hdf('data/parsed/sqr_mun.hdf', key='sqidx%i'% idx)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check no cells is overlapping for ANY pair of municipality indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "mun_adjacent = find_neighbor_shapes(kommuner)[['idx1', 'idx2']].values\n",
    "\n",
    "for (i1,i2) in mun_adjacent:    \n",
    "    if np.intersect1d(assignment_dict[i1], assignment_dict[i2]).size>0:\n",
    "        errors+= [(i1,i2)]\n",
    "        \n",
    "print (errors)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition municipality shapes into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kommuner  = read_parse_mun()\n",
    "\n",
    "select =  kommuner[(kommuner.to_assign) & (kommuner.cell_count>25000)]\n",
    "\n",
    "for idx in tqdm(select.index.tolist()):\n",
    "    \n",
    "    origin_geom= kommuner.iloc[idx].geometry\n",
    "    mun_df = pd.read_hdf('data/parsed/sqr_mun.hdf', 'sqidx%i' % idx)\n",
    "    mun_gdf = make_gdf_square_data(mun_df)\n",
    "    pre_part = pre_partition_area(mun_df, origin_geom)\n",
    "    \n",
    "    pre_part_suff = merge_insufficient(pre_part)\n",
    "    \n",
    "    assignment = assign_cells_partition(pre_part, mun_gdf)\n",
    "\n",
    "    mun_df = mun_df\\\n",
    "                .join(assignment)\\\n",
    "                .drop('geometry', axis=1)\n",
    "\n",
    "    for sub_idx, sub_df in mun_df.groupby('assignment'):\n",
    "        out_key = 'sqidx%i_%i' % (idx, sub_idx)\n",
    "        sub_df.to_hdf('data/parsed/sqr_mun_sub.hdf', key = out_key)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
